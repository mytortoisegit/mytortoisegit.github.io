---
title: 面试笔记
date: 2024-07-01 22:24:33
tags: 面试 记录
---





你好，我是， 老家在内蒙古呼和浩特的，大学毕业后就开始从事java相关开发，熟悉Java相关技术以及常见的各种框架，
同时可以熟练的运用，也熟悉各种数据库以及消息中间件，可以熟练的使用各种开发工具以及项目管理工具，上家公司是在通用技术控股有限公司做后端开发，
项目是一个互联网+健康医疗系统，包括智慧就医、在线问诊、健康管理、专科服务、健康商城等功能，涉及到4个web端、2个移动端、公众号、小程序等。
我在项目中主要负责根据产品提出的需求，分析并编写技术文档，同时完成相应功能的实现和测试，以及线上紧急问题的修复处理。

面试官：我这边没什么问题了你有什么问题要问我？ 业务线

面试要点：1、你们项目是单体架构吗 不是，我们是分布式架构，不同模块使用dubbo调用		

RabbitMQ：
	1、基于AMQP应用协议（高级消息队列协议），用于在分布式系统中异步传输消息。
	2、用于解耦、异步处理、流量削峰、数据同步
	3、主要包括生产者、消费者、交换机（Exchange）、队列（Queue）等核心概念。
	4、支持多种消息传递模型点对点   /发布/订阅等，
	5、交换机类型direct(点对点), fanout(发布/订阅), topic, headers  
	6、生产者发送消息到交换机，交换机通过配置路由信息，将消息投递到对应的队列中，消费者绑定队列，从队列中消费消息。
	7、可以通过设置队列和消息的持久化属性来保证消息在 RabbitMQ 重启后不丢失
	8、如何确保消息被正常消费：消费者消息确认机制自动确认和手动确认，自动确认是消费接收到消息后，mq会认为已经消费了，删除队列中对应消息，消费过程中异常，消息丢失
																	 手动确认是消息处理完，必须显式的发送一个确认给mq,收到ack后才删除消息，如果没收到，会重新加入队列																 或者放入死信队列，以此确保消息被消费一次
	9、死信队列用于存储无法被正常消费的队列，消息被拒绝、队列达到最大长度、队列中超时，

消息确认机制：自动ACK 消费者接收到消息后，消息立即从队列删除，不适用需要确保消息被成功消费的场景
			  手动ACK 消费者在成功处理完消息后，显示发送ack,   适用于需要确保消息被成功处理的场景
			 死信队列，消息失败次数过多时，进入死信队列，进行特殊处理。

如何保证消息不丢失？1.消息持久化标记
					2.绑定队列时，可标记为持久化队列
					3.手动消息确认，确保消费者，正确处理消息后，才从对列删除。
					4.生产者使用消息确认机制，确保消息成功到达服务器，如果未被确认，可以选择重发。
					
消息队列如何保证幂等性：1. 唯一消息ID，每条消息都带自身业务的唯一ID，消费者检查此id是否被消费，已处理跳过，未处理则处理并标记
						2. 操作本身是幂等操作，插入前检查数据是否已存在，更新使用唯一标识更新，删除检查是否存在再删除。
						3. 事务和消息队列的结合，消息确认机制，当生产者生成消息后，被消费者成功消费后返回给生成者消费成功标识，
						4. 在数据库中使用唯一约束，避免重复插入数据。
						
消息队列如何保证顺序消费：1.单一消费者，每个队列只有一个消费者。 缺点：处理能力有限
						  2.消费者并发控制，使用消费者窗口机制，确保每个消费者处理完当前消息之前不会收到新消息channel.basicQos(1);
						  3.消息确认机制，确保每条消息在成功处理后才进行下一条消息的处理。
					
Direct Exchange：适用于点对点精确匹配的场景，如任务调度、不同级别的日志处理。
Fanout Exchange：适用于广播消息的场景，如通知、事件更新、多服务同步。
Topic Exchange：适用于模糊匹配的场景，如日志聚合、事件驱动架构。
Headers Exchange：适用于复杂路由需求的场景，如企业消息总线。	 
		 		 
Spring MVC 主要用于构建 Web 应用，专注于请求处理和视图渲染。适合于需要精细控制配置和组件的应用。

Spring Boot  用于简化 Spring 应用的开发过程。它集成了 Spring MVC，并提供了自动配置、内嵌服务器等特性，极大地提高了开发效率。	
			
dubbo是高性能的 RPC （远程过程调用）框架，广泛应用于构建微服务、分布式服务架构中




mysql数据库：
			慢sql优化
					1.配置数据库启用慢查询日志
					2.找到查询慢的sql语句，使用EXPLAIN分析慢的原有以及索引使用情况。
					3.使用索引提高查询效率 使用索引，或者使用联合索引提高查询效率。
					4.优化sql语句，1）避免使用select * 返回过多无用数据
								   2）优化where子句，使用索引，避免全表扫描
									3）避免使用 like %d%
					5.选择性的使用子查询和联接
执行引擎：
		InnoDB：事务支持、行级锁定、外键支持、崩溃恢复，适用场景：适合需要事务支持、并发高、数据完整性要求较高的应用
		MyISAM: 全文索引、表级锁定、不支持事务，适用场景：适合读密集的应用，如日志分析系统、数据仓库等 
			

数据库处理并发事务时出现常见问题，脏读（读到未提交数据）、不可重复度（2次读取到数据不一致）、幻读 （一个事务俩次查询间，另一个事务插入或者删除了数据）
		

为解决并发问题：四种隔离级别，读未提交，读已提交，可重复读，可序列化
		默认： Oracle：读已提交   MySQL：可重复读


​				
事务处理的基本属性 ACID: 原子性、一致性、隔离性、持久性			
			
线程池的三大参数：核心线程数，最大线程数，任务队列

分布式锁：保证在多个节点同时访问时，只有一个节点能够获取锁并执行临界区代码，从而避免并发冲突。
		实现方式：基于redis

**分布式事务：**

在多个不同的数据库或服务中执行的一系列操作，这些操作作为一个整体被提交或回滚，以保证数据的一致性和完整性。要么全部成功，要么全部失败
	比如一个订单，要执行库存更新和订单创建，支付与订单状态更新，订单中涉及到积分或优惠券使用，

**解决方式**：在强一致性的要求场景下，可以使用2PC或3PC，			  在性能和灵活性要求高的场景下，可以使用选择TCC、SAGA或基于消息的事务（消息确认机制，消费者成功后返回给生产者）。		

​				
**redis:   String  hash    list  set  zset**
	常用的场景：1、缓存，目的减少数据库的查询压力，提高响应速度。
				2、会话存储， 目的存储用户会话信息。
				3、队列   目的任务队列、消息队列   lpush rpop
				4、排行榜/计数器 目的实时计算和排序。
				5、分布式锁  目的 在分布式系统中实现锁机制，避免资源竞争。
				
雪崩：大量的key同时过期，导致数据库访问激增甚至崩溃
	解决：1.缓存时间随机化：在设置缓存失效时间时，为每个时间加一个随机时间偏移，可以随机增加0-600秒
		  2.不设置过期时间，定期更新缓存，
		  3.缓存预热，定时将热点数据加载到缓存中，
		  4.使用锁机制，通过分布式锁来控制对数据库访问，只有获取到锁的请求可以访问，同时设置缓存。
穿透：缓存中没有数据，数据库也没有，不停的访问相同key

​	解决：查询数据库没有，设置null到缓存中。

​				
数据一致性：1.双写一致性控制，先写数据库，成功后更新缓存。先写缓存成功后再更新数据库，同时设置缓存过期时间，
			2.消息队列，当数据发生变化时，将数据发生到消息队列，由消费者异步处理缓存和数据库的更新。
			

多线程竞争的时候，				
轻量级锁  通过程序自旋实现cas

重量级锁  操作系统层面处理

偏向锁，默认锁给某一线程， 通过标签的形式实现
		当出现锁竞争的时候升级为 轻量级锁 升级到重量级锁
		
Spring Cloud组件系列		
	Eureka：服务发现和注册中心
	Ribbon：客户端负载均衡器
	Feign：声明式 HTTP 客户端
	Hystrix：熔断器
	Zuul：API 网关
	
spring   springmvc   mybatis   hibernate  struts  springboot  springcloud   mysql   
oracle  mongodb  redis  RabbitMQ  dubbo  zookeeper  linux  docker 


一个表student表  id 、  性别 、  分数字段，要求分别统计出数分数大于90分的男女人数

SELECT  gender,  COUNT(*) AS count  FROM  student  WHERE   score > 90   GROUP BY   gender;


Java集合框架 Collection、List、Set、Queue、Map
			List:有序可重复   
				ArrayList底层基于动态数组（默认10，扩容1.5倍），随机访问快，增删元素慢， 
				LinkedList基于双向链表，增删元素快，随机访问慢      
			Set：无序不可重复
				HashSet基于hashmap实现，
				LinkedHashSet 维护了一个双向链表来保持插入顺序
				TreeSet基于红黑树（一种自平衡二叉查找树）实现
			Map:
				hashmap: 基于数组和 链表（链表长度8转红黑树，长度变成6时转链表）实现的哈希表，使用hashcode值对16取模计算位置，使用链表或红黑树 解决哈希冲突的方法
						默认长度是16，扩容因子默认为 0.75，当元素超过 初始值*扩容因子时，触发扩容，扩容数组增大一倍，重新计算数组中元素位置。
						允许键和值都为null,
						线程不安全
				LinkedHashMap： 通过双向链表维护插入顺序或访问顺序
				ConcurrentHashMap：线程安全，使用了分段所，每一段相当于一个hashmap。			


数据库模型：关系型MySQL、PostgreSQL、Oracle、 SQL Server ，键值对key-value Redis,
			文档型MongoDB，图型，列存储型，



